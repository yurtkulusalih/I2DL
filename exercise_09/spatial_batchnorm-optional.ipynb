{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Spatial Batch Normalization\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <strong>Note:</strong> This exercise is optional and can be done for a better understanding of batch normalization. Also, when using batch normalization with PyTorch, you should be paying attention to the number of dimensions in the input (see <a href=\"https://pytorch.org/docs/stable/nn.html#batchnorm1d\">BatchNorm1d</a>, <a href=\"https://pytorch.org/docs/stable/nn.html#batchnorm2d\">BatchNorm2d</a> etc.)\n",
    "</div>\n",
    "\n",
    "We already saw that batch normalization is a very useful technique for training deep fully-connected networks. Batch normalization can also be used for convolutional networks, but we need to tweak it a bit; the modification will be called \"spatial batch normalization.\"\n",
    "\n",
    "Normally batch-normalization accepts inputs of shape `(N, D)` and produces outputs of shape `(N, D)`, where we normalize across the minibatch dimension `N`. For data coming from convolutional layers, batch normalization needs to accept inputs of shape `(N, C, H, W)` and produce outputs of shape `(N, C, H, W)` where the `N` dimension gives the minibatch size and the `(H, W)` dimensions give the spatial size of the feature map.\n",
    "\n",
    "If the feature map was produced using convolutions, then we expect the statistics of each feature channel to be relatively consistent both between different image sand different locations within the same image. Therefore spatial batch normalization computes a mean and variance for each of the `C` feature channels by computing statistics over both the minibatch dimension `N` and the spatial dimensions `H` and `W`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from exercise_code.layers import (\n",
    "    spatial_batchnorm_forward, \n",
    "    spatial_batchnorm_backward,\n",
    ")\n",
    "from exercise_code.tests.gradient_check import (\n",
    "    eval_numerical_gradient_array,\n",
    "    eval_numerical_gradient,\n",
    "    rel_error,\n",
    ")\n",
    "from exercise_code.tests.spatial_batchnorm_tests import (\n",
    "    test_spatial_batchnorm_forward,\n",
    "    test_spatial_batchnorm_backward,\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial batch normalization: forward\n",
    "\n",
    "In the file `exercise_code/layers.py`, implement the forward pass for spatial batch normalization in the function `spatial_batchnorm_forward`. Check your implementation by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_spatial_batchnorm_forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial batch normalization: backward\n",
    "In the file `exercise_code/layers.py`, implement the backward pass for spatial batch normalization in the function `spatial_batchnorm_backward`. Run the following to check your implementation using a numeric gradient check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_spatial_batchnorm_backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
